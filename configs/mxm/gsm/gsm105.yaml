model_parameters:
    name : 'HFVAE'
    encoder :
        name : 'HFCEncoder'
        input_dim : 5000
        hidden_dim : 500
        latent_dim : 50
        num_groups : 2
        architecture : 'GSM'
    decoder :
        name : 'HFCDecoder'
        latent_dim : 50
        output_dim : 5000
        batch_size : 500
        num_groups : 2
        architecture : 'GSM'
    spec:
      beta: [5.0, 1.0, 1.0, 10.0, 0.0] # template (gamma, 1, alpha, beta, 0.0)


experiment_parameters:
  name : 'PTVAEXperiment'
  seed : 50
  dataset : mxm
  data_path : 'resources/datasets/mxm'
  sparse: True
  labels: False
  save_path : 'results/mxm'
  batch_size : 500
  learning_rate : 5e-5
  use_cuda : True


trainer_parameters:
  max_epochs : 1000
  patience : 50 # used for early stopping , ignored if set to 0 - also depends on test_interval
  log_interval : 100 # log every 10th batch
  test_interval : 1  # evaluate on test(valid) every epoch
  track:
    loss_components: True # track and log all components of the loss
    perplexity: False


