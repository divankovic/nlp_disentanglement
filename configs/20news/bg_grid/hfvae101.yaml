model_parameters:
    name : 'HFVAE101'
    encoder :
        name : 'HFCEncoder'
        input_dim : 2000
        hidden_dim : 500
        latent_dim : 50
        num_groups : 2
        architecture : 'NVDM'
    decoder :
        name : 'HFCDecoder'
        latent_dim : 50
        output_dim : 2000
        batch_size : 500
        num_groups : 2
        architecture : 'NVDM'
    spec:
      beta: [1.0, 1.0, 1.0, 10.0, 0.0] # template (gamma, 1, alpha, beta, 0.0)


experiment_parameters:
  name : 'PTVAEXperiment'
  seed : 50
  dataset : 20news
  data_path : 'resources/datasets/20news/1'
  sparse: False
  labels: True
  save_path : 'results/base'
  batch_size : 500
  learning_rate : 5e-5
  use_cuda : True


trainer_parameters:
  max_epochs : 1000
  patience : 1000 # used for early stopping , ignored if set to 0 - also depends on test_interval
  log_interval : 10 # log every 10th batch
  test_interval : 1  # evaluate on test(valid) every epoch
  track:
    loss_components: True # track and log all components of the loss
    perplexity: False


