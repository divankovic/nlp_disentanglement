{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dorian/FER/master_thesis/src/base\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import probtorch\n",
    "from utils.file_handling import load_nparray\n",
    "from models.architectures.encoders.fc import HFVAEFCEncoder\n",
    "from models.architectures.decoders.fc import HFVAEFCDecoder\n",
    "from models.hfvae import HFVAE\n",
    "from multiprocessing import cpu_count\n",
    "from trainer import VAETrainer\n",
    "import time\n",
    "\n",
    "os.chdir('..')\n",
    "print(os.getcwd())\n",
    "# model parameters\n",
    "HIDDEN_DIM = 256\n",
    "LATENT_DIM = 50\n",
    "\n",
    "# training parameters\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 20\n",
    "LEARNING_RATE = 1e-3\n",
    "BETA1 = 0.90\n",
    "EPS = 1e-9\n",
    "CUDA = torch.cuda.is_available()\n",
    "\n",
    "# saving\n",
    "SAVE_PATH = 'results/hfvae'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch:  1 [     0/ 11314 (  0%)]\tLoss: 2.800763\n",
      "Train Epoch:  1 [  1280/ 11314 ( 11%)]\tLoss: 2.024806\n",
      "Train Epoch:  1 [  2560/ 11314 ( 22%)]\tLoss: 2.875154\n",
      "Train Epoch:  1 [  3840/ 11314 ( 34%)]\tLoss: 1.744349\n",
      "Train Epoch:  1 [  5120/ 11314 ( 45%)]\tLoss: 3.015428\n",
      "Train Epoch:  1 [  6400/ 11314 ( 56%)]\tLoss: 2.833321\n",
      "Train Epoch:  1 [  7680/ 11314 ( 67%)]\tLoss: 2.775266\n",
      "Train Epoch:  1 [  8960/ 11314 ( 79%)]\tLoss: 2.348330\n",
      "Train Epoch:  1 [ 10240/ 11314 ( 90%)]\tLoss: 1.751881\n",
      "====> Epoch: 1 Average loss: 2.5703\n",
      "====> Test set loss: 2.3904\n",
      "Train Epoch:  2 [     0/ 11314 (  0%)]\tLoss: 4.840169\n",
      "Train Epoch:  2 [  1280/ 11314 ( 11%)]\tLoss: 2.256938\n",
      "Train Epoch:  2 [  2560/ 11314 ( 22%)]\tLoss: 3.681406\n",
      "Train Epoch:  2 [  3840/ 11314 ( 34%)]\tLoss: 2.250000\n",
      "Train Epoch:  2 [  5120/ 11314 ( 45%)]\tLoss: 2.412110\n",
      "Train Epoch:  2 [  6400/ 11314 ( 56%)]\tLoss: 1.918739\n",
      "Train Epoch:  2 [  7680/ 11314 ( 67%)]\tLoss: 4.262239\n",
      "Train Epoch:  2 [  8960/ 11314 ( 79%)]\tLoss: 2.830435\n",
      "Train Epoch:  2 [ 10240/ 11314 ( 90%)]\tLoss: 2.364494\n",
      "====> Epoch: 2 Average loss: 2.5137\n",
      "====> Test set loss: 2.3847\n",
      "Train Epoch:  3 [     0/ 11314 (  0%)]\tLoss: 1.825593\n",
      "Train Epoch:  3 [  1280/ 11314 ( 11%)]\tLoss: 2.652063\n",
      "Train Epoch:  3 [  2560/ 11314 ( 22%)]\tLoss: 2.002700\n",
      "Train Epoch:  3 [  3840/ 11314 ( 34%)]\tLoss: 1.450996\n",
      "Train Epoch:  3 [  5120/ 11314 ( 45%)]\tLoss: 2.162727\n",
      "Train Epoch:  3 [  6400/ 11314 ( 56%)]\tLoss: 3.149599\n",
      "Train Epoch:  3 [  7680/ 11314 ( 67%)]\tLoss: 3.371564\n",
      "Train Epoch:  3 [  8960/ 11314 ( 79%)]\tLoss: 2.069420\n",
      "Train Epoch:  3 [ 10240/ 11314 ( 90%)]\tLoss: 3.010764\n",
      "====> Epoch: 3 Average loss: 2.4773\n",
      "====> Test set loss: 2.3605\n",
      "Train Epoch:  4 [     0/ 11314 (  0%)]\tLoss: 1.875727\n",
      "Train Epoch:  4 [  1280/ 11314 ( 11%)]\tLoss: 2.328274\n",
      "Train Epoch:  4 [  2560/ 11314 ( 22%)]\tLoss: 3.678205\n",
      "Train Epoch:  4 [  3840/ 11314 ( 34%)]\tLoss: 4.586171\n",
      "Train Epoch:  4 [  5120/ 11314 ( 45%)]\tLoss: 2.093951\n",
      "Train Epoch:  4 [  6400/ 11314 ( 56%)]\tLoss: 2.433265\n"
     ]
    }
   ],
   "source": [
    "kwargs = {'num_workers': cpu_count(), 'pin_memory': True} if CUDA else {'num_workers': cpu_count()}\n",
    "train_loader = torch.utils.data.DataLoader(load_nparray('resources/datasets/20_newsgroups/preprocessed/train_bow.txt'),\n",
    "                                         batch_size=BATCH_SIZE, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(load_nparray('resources/datasets/20_newsgroups/preprocessed/test_bow.txt'),\n",
    "                                        batch_size=BATCH_SIZE, shuffle=True, **kwargs)\n",
    "\n",
    "\n",
    "enc = HFVAEFCEncoder(input_dim=2000, hidden_dim=HIDDEN_DIM, latent_dim=LATENT_DIM)\n",
    "dec = HFVAEFCDecoder(latent_dim=LATENT_DIM, output_dim=2000, batch_size=BATCH_SIZE)\n",
    "model = HFVAE(encoder=enc, decoder=dec)\n",
    "model.cuda()\n",
    "model.double()\n",
    "optimizer =  torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, betas=(BETA1, 0.999))\n",
    "device = torch.device(\"cuda\" if CUDA else \"cpu\")\n",
    "\n",
    "VAETrainer(model, device, train_loader, test_loader, save_model_path=SAVE_PATH, probtorch=True).run(optimizer, NUM_EPOCHS)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# EVALUATION\n",
    "# model loading\n",
    "# model = HFVAE()\n",
    "# model.load_state_dics(torch.load('results/hfvae/model.pt'))\n",
    "# model.eval()\n",
    "\n",
    "# Embedding visualization\n",
    "\n",
    "\n",
    "\n",
    "# t-sne\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# BACKUP TRAINER\n",
    "# train_loader = torch.utils.data.DataLoader(load_nparray('resources/datasets/20_newsgroups/preprocessed/train_bow.txt'),\n",
    "#                                          batch_size=BATCH_SIZE, shuffle=True)\n",
    "# test_loader = torch.utils.data.DataLoader(load_nparray('resources/datasets/20_newsgroups/preprocessed/test_bow.txt'),\n",
    "#                                         batch_size=BATCH_SIZE, shuffle=True)\n",
    "#\n",
    "#\n",
    "# enc = HFVAEFCEncoder(input_dim=2000, hidden_dim=HIDDEN_DIM, latent_dim=LATENT_DIM)\n",
    "# dec = HFVAEFCDecoder(latent_dim=LATENT_DIM, output_dim=2000)\n",
    "# model = HFVAE(encoder=enc, decoder=dec)\n",
    "# model.cuda()\n",
    "# model.double()\n",
    "# optimizer =  torch.optim.Adam(list(model.parameters()), lr=LEARNING_RATE, betas=(BETA1, 0.999))\n",
    "#\n",
    "# def train(data, model, optimizer):\n",
    "#     epoch_elbo = 0.0\n",
    "#     model.train()\n",
    "#     N = 0\n",
    "#     for b, texts in enumerate(data):\n",
    "#         if texts.size()[0] == BATCH_SIZE:\n",
    "#             N += BATCH_SIZE\n",
    "#             if CUDA:\n",
    "#                 texts = texts.cuda()\n",
    "#             optimizer.zero_grad()\n",
    "#             q, p = model(texts)\n",
    "#             loss = model.loss_function(q, p)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             if CUDA:\n",
    "#                 loss = loss.cpu()\n",
    "#             epoch_elbo -= float(loss.item())\n",
    "#     return epoch_elbo / N\n",
    "#\n",
    "# def test(data, model):\n",
    "#     model.eval()\n",
    "#     epoch_elbo = 0.0\n",
    "#     N = 0\n",
    "#     for b, texts in enumerate(data):\n",
    "#         if texts.size()[0] == BATCH_SIZE:\n",
    "#             N += BATCH_SIZE\n",
    "#             if CUDA:\n",
    "#                 texts = texts.cuda()\n",
    "#             q, p = model.forward(texts)\n",
    "#             batch_elbo = -model.loss_function(q, p)\n",
    "#             if CUDA:\n",
    "#                 batch_elbo = batch_elbo.cpu()\n",
    "#             epoch_elbo += float(batch_elbo.item())\n",
    "#     return epoch_elbo / N\n",
    "#\n",
    "# for e in range(NUM_EPOCHS):\n",
    "#     train_start = time.time()\n",
    "#     train_elbo = train(train_loader, model, optimizer)\n",
    "#     train_end = time.time()\n",
    "#     test_start = time.time()\n",
    "#     test_elbo = test(test_loader, model)\n",
    "#     test_end = time.time()\n",
    "#     print('[Epoch %d] Train: ELBO %.4e (%ds) Test: ELBO %.4e (%ds)' % (\n",
    "#             e, train_elbo, train_end - train_start,\n",
    "#             test_elbo, test_end - test_start))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}