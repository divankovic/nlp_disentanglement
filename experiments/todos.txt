20 news
    - run with dataset from Srivastava (prodLDA), as everyone uses that dataset, good for comparison
    - classic NVDM
    - Beta VAE NVDM - change Beta
    - Factor VAE NVDM - change gamma
    - HFVAE NVDM - change beta, gamma

BeerReviews
    - classic NVDM
    - HFVAE NVDM single setup (independent groups, correletions inside the group)
    - HFVAE cocrete prior

EVALUATION
umap
use code for NPMI from 'topic_interpretability' repository - https://github.com/jhlau/topic_interpretability
    - wikipedia used as a reference corpus, could take up some time to calculate (~20min : from Coherence aware neural topic modeling)
word distributions
...

other - GSM/GSB/RSB (from Discovering discrete latent topics with neural variational inference)
            - a lot of extra math, minor improvements
      - multilayer encoder and decoder (from Neural Relational Topic Models for Scientific Article Analysis)
            - not complicated, improvements ok
      - model from Coherence aware neural topic modeling (NTM-F, NTM-FR, NTM-R : best) - uses word embeddings, really nice idea,
            - could be the simplest and most effective one to try out
      - ProdLDA / LDA
      - some extra useful datasets to maybe try sth out - https://archive.ics.uci.edu/ml/datasets/Bag+of+Words, already in BoW
